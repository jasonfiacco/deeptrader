{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_v7yDS2GZvGQ"
   },
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "9EjjJ4SLZ3Eu",
    "outputId": "5516a082-3ce3-4b92-ebbc-a0464baad653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-07 20:27:13--  http://acegames.in/MachineLearning/ALL_combined.csv\n",
      "Resolving acegames.in (acegames.in)... 162.222.226.133\n",
      "Connecting to acegames.in (acegames.in)|162.222.226.133|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6747467 (6.4M) [text/csv]\n",
      "Saving to: ‘ALL_combined.csv’\n",
      "\n",
      "\r",
      "ALL_combined.csv      0%[                    ]       0  --.-KB/s               \r",
      "ALL_combined.csv      0%[                    ]  47.64K   190KB/s               \r",
      "ALL_combined.csv      3%[                    ] 219.67K   438KB/s               \r",
      "ALL_combined.csv     12%[=>                  ] 795.19K  1.03MB/s               \r",
      "ALL_combined.csv     48%[========>           ]   3.13M  3.12MB/s               \r",
      "ALL_combined.csv    100%[===================>]   6.43M  5.68MB/s    in 1.1s    \n",
      "\n",
      "2020-02-07 20:27:15 (5.68 MB/s) - ‘ALL_combined.csv’ saved [6747467/6747467]\n",
      "\n"
     ]
    }
   ],
   "source": [
    " !wget http://acegames.in/MachineLearning/ALL_combined.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "v1__A_80ZvGW",
    "outputId": "a3c23018-59db-42f2-a899-f1f8d300acab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 7%\r",
      "\r",
      "Reading package lists... 7%\r",
      "\r",
      "Reading package lists... 7%\r",
      "\r",
      "Reading package lists... 7%\r",
      "\r",
      "Reading package lists... 65%\r",
      "\r",
      "Reading package lists... 65%\r",
      "\r",
      "Reading package lists... 65%\r",
      "\r",
      "Reading package lists... 65%\r",
      "\r",
      "Reading package lists... 72%\r",
      "\r",
      "Reading package lists... 72%\r",
      "\r",
      "Reading package lists... 73%\r",
      "\r",
      "Reading package lists... 73%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 82%\r",
      "\r",
      "Reading package lists... 85%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 94%\r",
      "\r",
      "Reading package lists... 94%\r",
      "\r",
      "Reading package lists... 95%\r",
      "\r",
      "Reading package lists... 95%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... Done\r\n",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree       \r\n",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... Done\r\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "Suggested packages:\n",
      "  libgle3\n",
      "The following NEW packages will be installed:\n",
      "  python-opengl\n",
      "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 496 kB of archives.\n",
      "After this operation, 5,416 kB of additional disk space will be used.\n",
      "\u001b[33m\r",
      "0% [Working]\u001b[0m\r",
      "            \r",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
      "Fetched 496 kB in 0s (5,104 kB/s)\n",
      "Selecting previously unselected package python-opengl.\n",
      "(Reading database ... 145113 files and directories currently installed.)\n",
      "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
      "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
      "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  xvfb\n",
      "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 783 kB of archives.\n",
      "After this operation, 2,266 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3 [783 kB]\n",
      "Fetched 783 kB in 0s (9,182 kB/s)\n",
      "Selecting previously unselected package xvfb.\n",
      "(Reading database ... 147468 files and directories currently installed.)\n",
      "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.3_amd64.deb ...\n",
      "Unpacking xvfb (2:1.19.6-1ubuntu4.3) ...\n",
      "Setting up xvfb (2:1.19.6-1ubuntu4.3) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading https://files.pythonhosted.org/packages/69/ec/8221a07850d69fa3c57c02e526edd23d18c7c05d58ed103e3b19172757c1/PyVirtualDisplay-0.2.5-py2.py3-none-any.whl\n",
      "Collecting EasyProcess\n",
      "  Downloading https://files.pythonhosted.org/packages/32/8f/88d636f1da22a3c573259e44cfefb46a117d3f9432e2c98b1ab4a21372ad/EasyProcess-0.2.10-py2.py3-none-any.whl\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
      "Successfully installed EasyProcess-0.2.10 pyvirtualdisplay-0.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install pyvirtualdisplay\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "224Jop6aZvGg"
   },
   "source": [
    "# 01. DQN\n",
    "\n",
    "[V. Mnih et al., \"Human-level control through deep reinforcement learning.\" Nature, 518\n",
    "(7540):529–533, 2015.](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n",
    "\n",
    "Reinforcement learning is known to be unstable or even to diverge when a nonlinear function approximator such as a neural network is used to represent the action-value (also known as $Q$) function. This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to $Q$ may significantly change the policy and therefore change the data distribution, and the correlations between the action-values ($Q$) and the target values $r + \\gamma \\max_{a'} Q(s', a')$.\n",
    "\n",
    "The authors suggest two key ideas to address these instabilities with a novel variant of Q-learning: Replay buffer and Fixed Q-target.\n",
    "\n",
    "#### Uniformly random sampling from Experience Replay Memory\n",
    "\n",
    "Reinforcement learning agent stores the experiences consecutively in the buffer, so adjacent ($s, a, r, s'$) transitions stored are highly likely to have correlation. To remove this, the agent samples experiences uniformly at random from the pool of stored samples $\\big( (s, a, r, s') \\sim U(D) \\big)$. See sample_batch method of ReplayBuffer class for more details.\n",
    "\n",
    "#### Fixed Q-target\n",
    "\n",
    "DQN uses an iterative update that adjusts the action-values ($Q$) towards target values that are only periodically updated, thereby reducing correlations with the target; if not, it is easily divergy because the target continuously moves. The Q-learning update at iteration $i$ uses the following loss function:\n",
    "\n",
    "$$\n",
    "L_i(\\theta_i) = \\mathbb{E}_{(s,a,r,s') \\sim U(D)} \\big[ \\big( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s, a; \\theta_i) \\big)^2 \\big]\n",
    "$$\n",
    "\n",
    "in which $\\gamma$ is the discount factor determining the agent’s horizon, $\\theta_i$ are the parameters of the Q-network at iteration $i$ and $\\theta_i^-$ are the network parameters used to compute the target at iteration $i$. The target network parameters $\\theta_i^-$ are only updated with the Q-network parameters ($\\theta_i$) every C steps and are held fixed between individual updates. ($C = 200$ in CartPole-v0)\n",
    "\n",
    "#### For more stability: Gradient clipping\n",
    "\n",
    "The authors also found it helpful to clip the error term from the update $r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s,a,;\\theta_i)$ to be between -1 and 1. Because the absolute value loss function $|x|$ has a derivative of -1 for all negative values of x and a derivative of 1 for all positive values of x, clipping the squared error to be between -1 and 1 corresponds to using an absolute value loss function for errors outside of the (-1,1) interval. This form of error clipping further improved the stability of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1tMH-DkZvGi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th2_PPebZvGn"
   },
   "source": [
    "## Replay buffer\n",
    "\n",
    "Typically, people implement replay buffers with one of the following three data structures:\n",
    "\n",
    "  - collections.deque\n",
    "  - list\n",
    "  - numpy.ndarray\n",
    "  \n",
    "**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of  *Get item* is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n",
    "\n",
    "Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). Whereas list is an array of pointers to objects, even when all of them are of the same type.\n",
    "\n",
    "Here, we are going to implement a replay buffer using numpy.ndarray.\n",
    "\n",
    "\n",
    "Reference: [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Iv-ih9ZvGo"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSLv_n3iZvGs"
   },
   "source": [
    "## Network\n",
    "\n",
    "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bl1I39D7ZvGt"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYHcWwsTZvGw"
   },
   "source": [
    "## DQN Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NGkeKDuZvGy"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "           \n",
    "            state = next_state\n",
    "            score += reward\n",
    "          # print(\"act reward\",score)\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "       # self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            self.env.render()\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        \n",
    "        #self.env.close()\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(\n",
    "            next_state\n",
    "        ).max(dim=1, keepdim=True)[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wz5FKV7-ZvG2"
   },
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZfOM5iXaY6b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pylab\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import gym as gym\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.currentRowIndex = 1\n",
    "        self.DataFrame = pd.read_csv(\"ALL_combined.csv\", sep=\",\")\n",
    "        self.DataFrame = self.DataFrame.drop([\"CloseTime\"], axis=1)\n",
    "        self.TotalRowCount = len(self.DataFrame.index)\n",
    "        #self.TotalRowCount = 22222\n",
    "        # CSV Features Coums 0 to 16 ( upto 16)\n",
    "        self.FeaturesLength = 15\n",
    "        self.HighIndex = 15\n",
    "        self.LowIndex = 16\n",
    "        # High Low, 16,17\n",
    "        print(\"Total DataBase row Count \", self.TotalRowCount)  # count\n",
    "        print(\"Total DataBase row lenght \", len(self.DataFrame.shape))\n",
    "        print(\" self.DataFrame  self.FeaturesLength  \",\n",
    "              self.DataFrame.iloc[self.currentRowIndex,  self.FeaturesLength])\n",
    "        print(\" self.DataFrame High \",\n",
    "              self.DataFrame.iloc[self.currentRowIndex, self.HighIndex])\n",
    "        print(\" self.DataFrame LowIndex \",\n",
    "              self.DataFrame.iloc[self.currentRowIndex, self.LowIndex])\n",
    "\n",
    "        self.reward = 0\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.done = False\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0.0, high=1.0, shape=self.DataFrame.iloc[self.currentRowIndex, 0:self.FeaturesLength].shape, dtype=np.float16)\n",
    "        self.observation = self.DataFrame.iloc[self.currentRowIndex,\n",
    "                                               0:self.FeaturesLength]\n",
    "        self.info = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.currentRowIndex = 1\n",
    "        self.observation = self.DataFrame.iloc[self.currentRowIndex,\n",
    "                                               0:self.FeaturesLength]\n",
    "        return self.observation\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.currentRowIndex < self.TotalRowCount-10:\n",
    "            self.currentRowIndex += 1\n",
    "            self.observation = self.DataFrame.iloc[self.currentRowIndex,\n",
    "                                                   : self.FeaturesLength]\n",
    "            self.done = False\n",
    "\n",
    "            if action == 1 and self.DataFrame.iloc[self.currentRowIndex, self.HighIndex] > 0:\n",
    "                self.reward = self.DataFrame.iloc[self.currentRowIndex,\n",
    "                                                  self.HighIndex]\n",
    "            elif action == 1 and self.DataFrame.iloc[self.currentRowIndex, self.HighIndex] < 0:\n",
    "                self.reward = -1 * \\\n",
    "                    self.DataFrame.iloc[self.currentRowIndex, self.LowIndex]\n",
    "\n",
    "            elif action == 0 and self.DataFrame.iloc[self.currentRowIndex, self.LowIndex] > 0:\n",
    "                self.reward = self.DataFrame.iloc[self.currentRowIndex,\n",
    "                                                  self.LowIndex]\n",
    "            elif action == 0 and self.DataFrame.iloc[self.currentRowIndex, self.LowIndex] < 0:\n",
    "                self.reward = -1 * \\\n",
    "                    self.DataFrame.iloc[self.currentRowIndex, self.HighIndex]\n",
    "\n",
    "        else:\n",
    "            self.done = True\n",
    "            self.reward = 0\n",
    "            self.observation = self.DataFrame.iloc[1, 0:self.FeaturesLength]\n",
    "\n",
    "        return self.observation, self.reward, self.done, self.info\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        print(\"Render Call\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "2k9QGDQfZvG3",
    "outputId": "707d6564-05fa-4202-ef62-998fbf77f775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DataBase row Count  37360\n",
      "Total DataBase row lenght  2\n",
      " self.DataFrame  self.FeaturesLength   0.0\n",
      " self.DataFrame High  0.0\n",
      " self.DataFrame LowIndex  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# environment\n",
    "env_id = \"CartPole-v0\"\n",
    "env = TradingEnv()\n",
    "#env = gym.make(env_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEImP5a6ZvG6"
   },
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0FBq_SLZvG7"
   },
   "outputs": [],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iosaOVefZvG_"
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zS8U21U_ZvHB",
    "outputId": "18f1efcd-340a-471a-b2ca-9b757f08acc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames =  100000000\n",
    "memory_size = 1000000\n",
    "batch_size = 1000\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 100000\n",
    "\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPbBD6ccZvHE"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "5LAUF_gzZvHF",
    "outputId": "5503bd16-960a-4c07-d6bb-ab17d4545b9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIIAAAE/CAYAAAA6+WhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb1rVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GIDu_rsxZvHT"
   },
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4UOThnDZvHV"
   },
   "outputs": [],
   "source": [
    "agent.env = gym.wrappers.Monitor(env, \"videos\", force=True)\n",
    "agent.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klDGNgUKZvHd"
   },
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SYMU5vpZvHf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "list_of_files = glob.glob(\"videos/*.mp4\")\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "ipython_show_video(latest_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TradingEnv.dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
